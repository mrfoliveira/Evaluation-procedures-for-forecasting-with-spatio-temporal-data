% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/workflows.R
\name{evaluate}
\alias{evaluate}
\title{Evalute the results of a predictive workflow}
\usage{
evaluate(wfRes, eval.function = get("regressionMetrics",
  asNamespace("performanceEstimation")), .keptTrain = TRUE, ...)
}
\arguments{
\item{wfRes}{a data frame (or list of data frames) containing the results of
a predictive workflow with columns \code{trues} and \code{preds} containing
the real and predicted values, respectively}

\item{eval.function}{the function to be used to calculate error metrics from \code{wfRes}}

\item{.keptTrain}{a Boolean indicating whether \code{.keepTrain} was
set to \code{TRUE} in calls to estimation methods. Only useful
if evaluation metrics need training data.}

\item{...}{parameters to pass to \code{eval.function}}
}
\value{
The results (or a list of results) of \code{eval.function} applied to 
the data frame (or list of data frames) in \code{wfRes}
}
\description{
Calculate evaluation metrics from the raw results of a workflow
}
